
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- This HTML was auto-generated from MATLAB code. To make changes, update the MATLAB code and republish this document.       --><title>線形予測と自己回帰モデル作成</title><meta name="generator" content="MATLAB 7.11"><link rel="schema.DC" href="../http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2010-05-27"><meta name="DC.source" content="lpcardemo.m"><link rel="stylesheet" type="text/css" href="../../../../matlab/demos/private/style.css"></head><body><div class="header"><div class="left"><a href="matlab:edit lpcardemo">エディターで lpcardemo.m を開く</a></div><div class="right"><a href="matlab:echodemo lpcardemo">コマンド ウィンドウで実行</a></div></div><div class="content"><h1>線形予測と自己回帰モデル作成</h1><!--introduction--><p>このデモは、自己回帰モデル作成と線形予測の関係を示すことを意図しています。線形予測と自己回帰モデル作成という 2 つの問題は、同じ数値結果を得ることが可能です。両方の問題の最終的な目的は、線形フィルターのパラメーターを確定することです。しかし、それぞれの問題で使われるフィルターは異なります。</p><!--/introduction--><h2>目次</h2><div><ul><li><a href="#1">はじめに</a></li><li><a href="#2">入力が白色ノイズである全極フィルターを使用した AR 信号の生成</a></li><li><a href="#5">Yule-Walker 法を使用した信号からの AR モデルの検出</a></li><li><a href="#6">AR モデルと AR 信号の比較</a></li><li><a href="#8">LPC を使用した線形予測の実行</a></li><li><a href="#10">実際の信号と予測信号の比較</a></li><li><a href="#11">予測誤差の比較</a></li></ul></div><h2>はじめに<a name="1"></a></h2><p>線形予測の目的は、過去のサンプルの線形結合に基づいて、自己回帰プロセスの今後のサンプルを的確に予測できる FIR フィルターを決定することです。実際の自己回帰信号と予測信号の差は、予測誤差と呼ばれます。理想的には、この誤差が白色ノイズです。</p><p>自己回帰モデル作成の目的は、白色ノイズによって励起されたとき、モデル化する自己回帰プロセスと同じ統計値を持つ信号を生成する全極 IIR フィルターを決定することです。</p><h2>入力が白色ノイズである全極フィルターを使用した AR 信号の生成<a name="2"></a></h2><p>LPC 関数と FIR フィルターを使用して、目的の自己回帰信号を作成するために使用するパラメーターを生成します。ここでは FIR1 および LPC の使用は重要ではありません。たとえば、d を [1 1/2 1/3 1/4 1/5 1/6 1/7 1/8] などの単純な数値で置き換え、p0 を 1e-6 などに置き換えることができますが、フィルターの形の方が扱いやすいため、これを使用します。</p><pre class="codeinput">b = fir1(1024, .5);
[d,p0] = lpc(b,7);
</pre><p>自己回帰信号を生成するには、分散 p0 の白色ガウス ノイズを使用して全極フィルターを励起します。分散 p0 を取得するには、ノイズ発生器で 'gain' 項として SQRT(p0) を使用しなければなりません。</p><pre class="codeinput">randn(<span class="string">'state'</span>,pi); <span class="comment">% Allow reproduction of exact experiment</span>
u = sqrt(p0)*randn(8192,1); <span class="comment">% White gaussian noise with variance p0</span>
</pre><p>ここで、AR 信号を生成するため、白色ガウス ノイズ信号と全極フィルターを使用します。</p><pre class="codeinput">x = filter(1,d,u);
</pre><h2>Yule-Walker 法を使用した信号からの AR モデルの検出<a name="5"></a></h2><p>Yule-Walker 式を解くことで、指定された信号 x の統計値と一致する統計値を持つ AR 信号を白色ノイズによって励起されたときに生成する全極フィルターのパラメーターを決定できます。これは、自己回帰モデル作成と呼ばれます。Yule-Walker 式を解くには、自己相関関数 x を推定する必要があります。Levinson アルゴリズムを使用すると、効率的に Yule-Walker 式を解くことができます。ここでは、関数 ARYULE を使用します。</p><pre class="codeinput">[d1,p1] = aryule(x,7);
</pre><h2>AR モデルと AR 信号の比較<a name="6"></a></h2><p>次に、AR 信号 x をモデル化するために使用した全極フィルターの周波数応答を計算します。フィルターが白色ガウス ノイズによって励起されたとき、周波数応答の振幅の二乗に白色ノイズ入力の分散を乗算すると、このフィルターの出力のパワー スペクトル密度が得られることはよく知られています。この出力パワー スペクトル密度を計算する 1 つの方法として、関数 FREQZ を使用します。</p><pre class="codeinput">[H1,w1]=freqz(sqrt(p1),d1);
</pre><p>自己回帰信号 x のモデル化がどの程度適切かを確認するため、関数 FREQZ を使用して計算したモデルの出力のパワー スペクトル密度と、PERIODOGRAM スペクトル オブジェクトを使用して計算した x のパワー スペクトル密度の推定値を重ね合わせます。ピリオドグラムは 2*pi でスケーリングされ、片側であることに注意してください。比較するにはピリオドグラムを調整する必要があります。</p><pre class="codeinput">s = spectrum.periodogram;
Hpsd = psd(s,x);
plot(Hpsd); hold <span class="string">on</span>;
hp = plot(w1/pi,20*log10(2*abs(H1)/(2*pi)),<span class="string">'r'</span>); <span class="comment">% Scale to make one-sided PSD</span>
set(hp,<span class="string">'LineWidth'</span>,2);
xlabel(<span class="string">'Normalized frequency (\times \pi rad/sample)'</span>)
ylabel(<span class="string">'One-sided PSD (dB/rad/sample)'</span>)
legend(<span class="string">'PSD estimate of x'</span>,<span class="string">'PSD of model output'</span>)
</pre><img vspace="5" hspace="5" src="../lpcardemo_01.png" alt=""> <h2>LPC を使用した線形予測の実行<a name="8"></a></h2><p>線形予測の問題に戻ります。まず FIR 予測フィルターを決定します。このためには LPC を使用しますが、LPC の結果は若干の解釈が必要です。LPC はホワイトニング フィルター A(z) 全体の係数を返します。このフィルターは、自己回帰信号 x を入力として受け取り、予測誤差を出力として返します。ただし、A(z) の予測フィルターは形式 B(z) = 1- A(z) で埋め込まれています (ここで、B(z) が予測フィルター)。LPC で計算した係数と誤差分散は、実質的には関数 ARYULE で計算した係数と誤差分散と同じですが、その解釈が異なります。</p><pre class="codeinput">[d2,p2] = lpc(x,7);
[d1.', d2.']
</pre><pre class="codeoutput">
ans =

    1.0000    1.0000
   -3.5020   -3.5020
    6.8764    6.8764
   -9.1668   -9.1668
    8.7773    8.7773
   -6.0146   -6.0146
    2.7617    2.7617
   -0.6811   -0.6811

</pre><p>上記の説明のように A(z) から B(z) を抽出し、FIR 線形予測子フィルターを使用して、過去の値の線形結合に基づき、自己回帰信号の今後の値の推定値を取得します。</p><pre class="codeinput">xh=filter(-d2(2:end),1,x);
</pre><h2>実際の信号と予測信号の比較<a name="10"></a></h2><p>7 タップ FIR 予測フィルターを使用して実行した内容を把握するため、元の自己回帰信号と、線形予測子から得られた信号推定値をプロットします (200 サンプル)。ここで、予測フィルターの 1 サンプル遅延を考慮します。</p><pre class="codeinput">cla
stem([x(2:end),xh(1:end-1)]);
xlabel(<span class="string">'Sample time'</span>);
ylabel(<span class="string">'Signal value'</span>);
legend(<span class="string">'Original autoregressive signal'</span>,<span class="string">'Signal estimate from linear predictor'</span>)
axis([0 200 -0.08 0.1])
</pre><img vspace="5" hspace="5" src="../lpcardemo_02.png" alt=""> <h2>予測誤差の比較<a name="11"></a></h2><p>予測誤差パワー (分散) は、LPC の 2 番目の出力として返されます。その値は、理論的には AR モデル作成の問題で全極フィルターを励起する白色ノイズの分散 (p1) と同じです。予測誤差自体からも、この分散を推定できます。</p><pre class="codeinput">p3 = norm(x(2:end)-xh(1:end-1),2)^2/(length(x)-1);
</pre><p>次の値は、すべて理論的に同じではありません。違いは、これに含まれるさまざまな計算および近似誤差が原因です。</p><pre class="codeinput">[p0,p1,p2,p3]
</pre><pre class="codeoutput">
ans =

  1.0e-005 *

    0.5127    0.5517    0.5517    0.5192

</pre><p class="footer">Copyright 1988-2005 The MathWorks, Inc.<br>Published with MATLAB&reg; 7.11</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!-- ##### SOURCE BEGIN ##### %% Linear Prediction and Autoregressive Modeling % This demo is intended to show the relationship between autoregressive % modeling and linear prediction. Linear prediction and autoregressive % modeling are two different problems that can yield the same numerical % results. In both cases, the ultimate goal is to determine the parameters % of a linear filter. However, the filter used in each problem is % different.  % Copyright 1988-2005 The MathWorks, Inc. % $Revision: 1.1.4.2.2.1 $  $Date: 2010/07/29 21:29:04 $  %% Introduction % In the case of linear prediction, the intention is to determine an FIR % filter that can optimally predict future samples of an autoregressive % process based on a linear combination of past samples. The difference % between the actual autoregressive signal and the predicted signal is % called the prediction error. Ideally, this error is white noise. % % For the case of autoregressive modeling, the intention is to determine an % all-pole IIR filter, that when excited with white noise produces a signal % with the same statistics as the autoregresive process that we are trying % to model.  %% Generate an AR Signal using an All-Pole Filter with White Noise as Input % Here we use the LPC function and an FIR filter simply to come up with % parameters we will use to create the autoregressive signal we will work % with. The use of FIR1 and LPC are not critical here. For example, we % could replace d with something as simple as [1 1/2 1/3 1/4 1/5 1/6 1/7 % 1/8] and p0 with something like 1e-6. But the shape of this filter is % nicer so we use it instead. b = fir1(1024, .5); [d,p0] = lpc(b,7);  %%  % To generate the autoregressive signal, we will excite an all-pole filter % with white gaussian noise of variance p0. Notice that to get variance p0, % we must use SQRT(p0) as the 'gain' term in the noise generator. randn('state',pi); % Allow reproduction of exact experiment u = sqrt(p0)*randn(8192,1); % White gaussian noise with variance p0  %%  % We now use the white gaussian noise signal and the all-pole filter to % generate an AR signal. x = filter(1,d,u);  %% Find AR Model from Signal using the Yule-Walker Method % Solving the Yule-Walker equations, we can determine the parameters for an % all-pole filter that when excited with white noise will produce an AR % signal whose statistics match those of the given signal, x. Once again, % this is called autoregressive modeling. In order to solve the Yule-Walker % equations, it is necessary to estimate the autocorrelation function of x. % The Levinson algorithm is used then to solve the Yule-Walker equations in % an efficient manner. The function ARYULE does all this for us. [d1,p1] = aryule(x,7);  %% Compare AR Model with AR Signal % We now would like to compute the frequency response of the all-pole % filter we have just used to model the AR signal x. It is well-known that % the power spectral density of the output of this filter, when the filter % is excited with white gaussian noise is given by the magnitude-squared of % its frequency response multiplied by the variance of the white-noise % input. One way to compute this output power spectral density is by using % FREQZ as follows: [H1,w1]=freqz(sqrt(p1),d1);  %%  % In order to get an idea of how well we have modeled the autoregressive % signal x, we overlay the power spectral density of the output of the % model, computed using FREQZ, with the power spectral density estimate of % x, computed using the PERIODOGRAM spectrum object. Notice that the % periodogram is scaled by 2*pi and is one-sided. We need to adjust for % this in order to compare. s = spectrum.periodogram; Hpsd = psd(s,x); plot(Hpsd); hold on; hp = plot(w1/pi,20*log10(2*abs(H1)/(2*pi)),'r'); % Scale to make one-sided PSD set(hp,'LineWidth',2); xlabel('Normalized frequency (\times \pi rad/sample)') ylabel('One-sided PSD (dB/rad/sample)') legend('PSD estimate of x','PSD of model output')  %% Use LPC to Perform Linear Prediction % We now turn to the linear prediction problem. Here we try to determine an % FIR prediction filter. We use LPC to do so, but the result from LPC % requires a little interpretation. LPC returns the coefficients of the % entire whitening filter A(z), this filter takes as input the % autoregressive signal x and returns as output the prediction error. % However, A(z) has the prediction filter embedded in it, in the form B(z) % = 1- A(z), where B(z) is the prediction filter. Note that the % coefficients and error variance computed with LPC are essentially the % same as those computed with ARYULE, but their interpretation is different. [d2,p2] = lpc(x,7); [d1.', d2.']  %%  % We now extract B(z) from A(z) as described above to use the FIR linear % predictor filter to obtain an estimate of future values of the % autoregressive signal based on linear combinations of past values. xh=filter(-d2(2:end),1,x);  %% Compare Actual and Predicted Signals % To get a feeling for what we have done with a 7-tap FIR prediction % filter, we plot (200 samples) of the original autoregressive signal along % with the signal estimate resulting from the linear predictor keeping in % mind the one-sample delay in the prediction filter. cla stem([x(2:end),xh(1:end-1)]); xlabel('Sample time'); ylabel('Signal value'); legend('Original autoregressive signal','Signal estimate from linear predictor') axis([0 200 -0.08 0.1])  %% Compare Prediction Errors % The prediction error power (variance) is returned as the second output % from LPC. Its value is (theoretically) the same as the variance of the % white noise driving the all-pole filter in the AR modeling problem (p1). % Another way of estimating this variance is from the prediction error % itself: p3 = norm(x(2:end)-xh(1:end-1),2)^2/(length(x)-1);   %% % All of the following values are theoretically the same. The % differences are due to the various computation and approximation errors % herein. [p0,p1,p2,p3]   displayEndOfDemoMessage(mfilename)  ##### SOURCE END ##### --></body></html>