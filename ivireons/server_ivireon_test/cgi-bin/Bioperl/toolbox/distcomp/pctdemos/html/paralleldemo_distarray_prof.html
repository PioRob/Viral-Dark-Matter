
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Profiling Load Unbalanced Codistributed Arrays</title><meta name="generator" content="MATLAB 7.11"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2010-04-23"><meta name="DC.source" content="paralleldemo_distarray_prof.m"><link rel="stylesheet" type="text/css" href="../../../matlab/demos/private/style.css"></head><body><div class="header"><div class="left">This demo can run only in pmode</div></div><div class="content"><h1>Profiling Load Unbalanced Codistributed Arrays</h1><!--introduction--><p>The example in this demo uses an unevenly distributed array to show how to use the profiler when dealing with implicit communication.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#3">The Algorithm</a></li><li><a href="#10">The Busy Line Table in the Function Detail Report</a></li><li><a href="#15">Observing Codistributed Array Operations in Plot View</a></li><li><a href="#17">The Data Received Plot</a></li></ul></div><p><b>Prerequisites</b>:</p><div><ul><li>Interactive Parallel Mode in Parallel Computing Toolbox&#8482; (See <tt>pmode</tt> in the users guide.)</li><li><a href="paralleltutorial_parprofile.html">Using the Parallel Profiler in Pmode</a></li></ul></div><p>This demo demonstrates how to use the parallel profiler in the case of an unevenly distributed array. The easiest way to create a codistributed array is to pass a <tt>codistributor</tt> as an argument, such as in <tt>rand(N, codistributor)</tt>. This evenly distributes your matrix of size N between your MATLAB&reg; workers. To get unbalanced data distribution, you can get some number of columns of a codistributed array as a function of <tt>labindex</tt>.</p><p>The plots in this demo are produced from a 12-node MATLAB cluster. Everything else is shown running under a four-node local scheduler.</p><h2>The Algorithm<a name="3"></a></h2><p>The algorithm we chose for this codistributed array is relatively simple.  We generate a large matrix such that each lab gets an approximately 512-by-512 submatrix, except for the first lab. The first lab receives only one column of the matrix and the other columns are assigned to the last lab. Thus, on a four-lab cluster, lab 1 keeps only a 1-by-512 column, labs 2 and 3 have their allotted partitions, and lab 4 has its allotted partition plus the additional columns (left over from lab 1). The end result is an unbalanced workload when doing zero communication element-wise operations (such as <tt>sin</tt>) and communication delays with data parallel operations (such as <tt>codistributed/mtimes</tt>). We start with a data parallel operation first (<tt>codistributed/mtimes</tt>). We then perform, in a loop, <tt>sqrt</tt>, <tt>sin</tt>, and inner product operations, all of which only operate on individual elements of the matrix.</p><p>The MATLAB file code for this example can be found in: <a href="matlab:edit('pctdemo_aux_profdistarray')">pctdemo_aux_profdistarray</a></p><p>In this example, the size of the matrix differs depending on the number of MATLAB workers (<tt>numlabs</tt>). However, it takes approximately the same amount of computation time (not including communication) to run this demo on any cluster, so you can try using a larger cluster without having to wait a long time.</p><pre class="codeinput">P&gt;&gt; labBarrier; <span class="comment">% synchronize all the labs</span>
</pre><pre class="codeinput">P&gt;&gt; mpiprofile reset;
P&gt;&gt; mpiprofile on;
P&gt;&gt; pctdemo_aux_profdistarray();
</pre><pre>1    This lab has 1024 rows and 1 columns of a codistributed array
     Calling mtimes on codistributed arrays
     Calling embarrassingly parallel math functions (i.e. no communication is required)
     on a codistributed array.
     Done</pre><pre>2    This lab has 1024 rows and 256 columns of a codistributed array
     Calling mtimes on codistributed arrays
     Calling embarrassingly parallel math functions (i.e. no communication is required)
     on a codistributed array.
     Done</pre><pre>3    This lab has 1024 rows and 256 columns of a codistributed array
     Calling mtimes on codistributed arrays
     Calling embarrassingly parallel math functions (i.e. no communication is required)
     on a codistributed array.
     Done</pre><pre>4    This lab has 1024 rows and 511 columns of a codistributed array
     Calling mtimes on codistributed arrays
     Calling embarrassingly parallel math functions (i.e. no communication is required)
     on a codistributed array.
     Done</pre><pre class="codeinput">P&gt;&gt; mpiprofile viewer;
</pre><pre>1    Sending  pmode lab2client  to the MATLAB client for asynchronous evaluation.</pre><p>First, browse the Function Summary Report, making sure it is sorted by the execution time by clicking the <b>Total Time</b> column. Then follow the link for the top-level function (which should be <tt>pctdemo_aux_profdistarray</tt>) to see the Function Detail Report.</p><h2>The Busy Line Table in the Function Detail Report<a name="10"></a></h2><p>Each MATLAB function entry has its own <b>Busy Line</b> table, which is useful if you want to profile multiple programs or demos at the same time.</p><div><ul><li>In the <b>Function Detail Report</b>, observe the communication information for the executed MATLAB code on a line-by-line basis.</li></ul></div><div><ul><li>Compare profiling information using the Busy Line table. Click <b>Compare max vs. min TotalTime</b>. Observe the Busy Line table and check to see which line numbers took the most time by sorting the time field using the drop-down list. There are no for-loops in this code and no increasing complexity as you saw in the previous <a href="paralleldemo_drange_prof.html">Profiling Parallel Work Distribution</a> demo. However, there still is a large difference in computation load between the labs. Look at the <tt>sqrt( sin( D .* D ) );</tt> line.</li></ul></div><p><img vspace="5" hspace="5" src="paralleldemo_distarray_proffileopts.png" alt=""> </p><p><img vspace="5" hspace="5" src="paralleldemo_distarray_profblt.png" alt=""> </p><p>Despite the fact that no communication is required for this element-wise operation, the performance is not optimal, because some labs do more work than others. In the second row, (<tt>D*D*D</tt>), the total time taken is the same on both labs. However, the <b>Data Rec</b> and <b>Data Sent</b> columns show a large difference in the amount of data sent and received. The time taken for this <tt>mtimes</tt> is similar on all labs, because the codistributed array communication implicitly synchronizes all the labs.</p><p>In the ninth column (from the left)  of the Busy Line table, a bar shows the percentage for the selected field (using the <b>Sort busy lines</b> list box). These bars can also be used to visually compare <b>Total Time</b>, and <b>Data Sent</b> or <b>Data Received</b> of the main and comparison labs.</p><h2>Observing Codistributed Array Operations in Plot View<a name="15"></a></h2><p>If you click the relevant function name and are in the <b>Function Detail Report</b>, you get more specific information about a codistributed array operation.</p><div><ul><li>To get the inter-lab communication data click <tt>Plot All PerLab Communication</tt>. In the first figure, you can see lab 1 transferring the most amount of data, and the last lab (lab 12) transferring the least amount of data.</li><li>To go back to the <b>Function Summary Report</b>, click <b>Home</b> and then click on the <tt>pctdemo_aux_profdistarray</tt> link to view the Busy Line table again.</li></ul></div><p>Using the comparisons, you can also see the amount of data communicated between each lab. This is constant for all labs except for the first and last labs. When there is no explicit communication, this indicates a distribution problem. In a typical codistributed array <tt>mtimes</tt> operation, labs that have the least amount of data (e.g., lab 1) receive all the required data from their neighboring labs (e.g., lab 2).</p><h2>The Data Received Plot<a name="17"></a></h2><p><img vspace="5" hspace="5" src="paralleldemo_distarray_profrimage.png" alt=""> </p><p>In this <b>Data Received Per Lab</b> plot, there is a significant decrease in the amount of data transferred by the last lab and an increase in the amount transferred by the first lab. Observing the Receive Communication Time plot (not shown) further illustrates that there is something different going on in the first lab. That is, the first lab is spending the longest amount of time in communication.</p><p>As you can see, the uneven distribution of a matrix causes unnecessary communication delays when using data parallel codistributed array operations and uneven work distribution with task parallel (no communication) operations. In addition, labs (like the first lab in this demo) that are receiving more data start with the least amount of data prior to the codistributed array operation.</p><p class="footer">Copyright 2007-2010 The MathWorks, Inc.<br>
          Published with MATLAB&reg; 7.11</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!--
##### SOURCE BEGIN #####
%% Profiling Load Unbalanced Codistributed Arrays
% The example in this demo uses an unevenly distributed array
% to show how to use the profiler when dealing with implicit communication.

%   Copyright 2007-2010 The MathWorks, Inc.

%% 
% *Prerequisites*:
%
% * Interactive Parallel Mode in Parallel Computing Toolbox(TM) (See
% |pmode| in the users guide.)
% * <paralleltutorial_parprofile.html Using the Parallel Profiler in Pmode>

%%
% This demo demonstrates how to use the parallel profiler in the case of an
% unevenly distributed array. The easiest way to create a codistributed array 
% is to pass a |codistributor| as an argument, such as in |rand(N, codistributor)|. 
% This evenly distributes your matrix of size N between your MATLAB(R) workers. 
% To get unbalanced data distribution, you can get some number of columns of a
% codistributed array as a function of |labindex|. 
%
% The plots in this demo are produced from a 12-node MATLAB
% cluster. Everything else is shown running
% under a four-node local scheduler.

%% The Algorithm
% The algorithm we chose for this codistributed array is relatively simple.  We
% generate a large matrix such that each lab gets an approximately 512-by-512
% submatrix, except for the first lab. The first lab receives only one
% column of the matrix and the other columns are assigned to the last lab.
% Thus, on a four-lab cluster, lab 1 keeps only a 1-by-512 column, labs 2
% and 3 have their allotted partitions, and lab 4 has its allotted partition
% plus the additional columns (left over from lab 1). The end result is an
% unbalanced workload when doing zero communication element-wise operations
% (such as |sin|) and communication delays with data parallel operations
% (such as |codistributed/mtimes|). We start with a data parallel operation first
% (|codistributed/mtimes|). We then perform, in a loop, |sqrt|, |sin|, and inner
% product operations, all of which only operate on individual elements of
% the matrix.
%
% The MATLAB file code for this example can be found in:
% <matlab:edit('pctdemo_aux_profdistarray') pctdemo_aux_profdistarray>

%%
% In this example, the size of the matrix differs depending on the number
% of MATLAB workers (|numlabs|). However, it takes approximately the same
% amount of computation time (not including communication) to run this demo
% on any cluster, so you can try using a larger cluster without having to
% wait a long time.

labBarrier; % synchronize all the labs
mpiprofile reset;
mpiprofile on;
pctdemo_aux_profdistarray();
mpiprofile viewer;


%%
% First, browse the Function Summary Report, making sure it is sorted
% by the execution time by clicking the *Total Time*
% column. Then follow the link for the top-level function (which should be
% |pctdemo_aux_profdistarray|) to see the Function Detail Report.

%%      The Busy Line Table in the Function Detail Report
% Each MATLAB function entry has its own *Busy Line* table, which is useful if
% you want to profile multiple programs or demos at the same time.
%
% * In the *Function Detail Report*, observe the communication information
% for the executed MATLAB code on a line-by-line basis. 
%
% * Compare profiling information using the Busy Line table. Click *Compare
% max vs. min TotalTime*. Observe the Busy Line table and check to see
% which line numbers took the most time by sorting the time field using the
% drop-down list. There are no for-loops in this code and no increasing
% complexity as you saw in the previous <paralleldemo_drange_prof.html
% Profiling Parallel Work Distribution> demo. However, there still 
% is a large difference in computation
% load between the labs. Look at the |sqrt( sin( D .* D ) );| line.

%%
% <<paralleldemo_distarray_proffileopts.png>>

%%
% <<paralleldemo_distarray_profblt.png>>

%%
% Despite the fact that no communication is required for this element-wise
% operation, the performance is not optimal, because some labs do more work
% than others. In the second row, (|D*D*D|), the total time taken is the
% same on both labs. However, the *Data Rec*
% and *Data Sent* columns show a large difference in the amount of data
% sent and received. The time taken for this |mtimes| is similar on all
% labs, because the codistributed array communication implicitly synchronizes 
% all the labs.

%%
% In the ninth column (from the left)  of the Busy Line table, a
% bar shows the percentage for the selected field (using the *Sort busy
% lines*
% list box). These bars can also be used to visually compare *Total Time*,
% and *Data Sent* or *Data Received* of the main and comparison labs. 
%

%% Observing Codistributed Array Operations in Plot View
% If you click the relevant function name and are in the *Function Detail
% Report*, you get more specific information about a codistributed array 
% operation.

%%
% * To get the inter-lab communication data click |Plot All PerLab
% Communication|. In the first figure, you can see lab 1 transferring the
% most amount of data, and the last lab (lab 12) transferring the least
% amount of data.
% * To go back to the *Function Summary Report*, click *Home* and then 
% click on the |pctdemo_aux_profdistarray| link to view the Busy Line table
% again.
% 
% Using the comparisons, you can also see the amount of data communicated
% between each lab. This is constant for all labs except for the first and
% last labs. When there is no explicit communication, this indicates a
% distribution problem. In a typical codistributed array |mtimes| operation, 
% labs that have the least amount of data (e.g., lab 1) receive all the 
% required data from their neighboring labs (e.g., lab 2). 

%% The Data Received Plot 
% <<paralleldemo_distarray_profrimage.png>>

%% 
% In this *Data Received Per Lab* plot, there is a significant decrease
% in the amount of data transferred by the last lab and an increase in the
% amount transferred by the first lab. Observing the Receive Communication
% Time plot (not shown) further illustrates that there is something
% different going on in the first lab. That is, the first lab is spending
% the longest amount of time in communication.

%%
% As you can see, the uneven distribution of a matrix causes unnecessary
% communication delays when using data parallel codistributed array operations 
% and uneven work distribution with task parallel (no communication) operations.
% In addition, labs (like the first lab in this demo) that are receiving more
% data start with the least amount of data prior to the codistributed array
% operation.

displayEndOfDemoMessage(mfilename)

##### SOURCE END #####
--></body></html>